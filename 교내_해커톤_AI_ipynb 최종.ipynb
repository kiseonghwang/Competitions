{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d9749023eedf44fab71c59a9c9a6f16d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_43a34912229044ee9a0872cdbb280419","IPY_MODEL_9baf6ebc91ba4edda96abbf277e0e3d6","IPY_MODEL_8e3da8348b9d4661a996448cf1c8af9f"],"layout":"IPY_MODEL_afe65688079a4130be4d2b61c94bdaa0"}},"43a34912229044ee9a0872cdbb280419":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab1ba0164a204e56b03ec3be0359bde7","placeholder":"â€‹","style":"IPY_MODEL_61c98a7edcd04aee818ce35f6df3de1e","value":"Loading checkpoint shards: 100%"}},"9baf6ebc91ba4edda96abbf277e0e3d6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7cae7169102b4981ae2785280cb4de00","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_42f14a7686504cc8a932f110b0333c6a","value":28}},"8e3da8348b9d4661a996448cf1c8af9f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3cfd11c6a6044dca996dee2e9b32ff0","placeholder":"â€‹","style":"IPY_MODEL_f6901829b508423d8d482207231e6465","value":" 28/28 [02:28&lt;00:00,  4.66s/it]"}},"afe65688079a4130be4d2b61c94bdaa0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab1ba0164a204e56b03ec3be0359bde7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61c98a7edcd04aee818ce35f6df3de1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7cae7169102b4981ae2785280cb4de00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42f14a7686504cc8a932f110b0333c6a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c3cfd11c6a6044dca996dee2e9b32ff0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6901829b508423d8d482207231e6465":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"FuXIFTFapAMI","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4653e8fe-2c4b-43ef-fc82-b8c997feb148","executionInfo":{"status":"ok","timestamp":1704919581764,"user_tz":-540,"elapsed":99232,"user":{"displayName":"í™©ê¸°ì„±","userId":"00510822396737292722"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.10/dist-packages (0.0.25)\n","Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.2.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.31.0)\n","Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (3.0.1)\n","Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.2)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (2.1.2)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (8.1.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2023.11.17)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.8->flask-ngrok) (2.1.3)\n","Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n","Requirement already satisfied: gTTS in /usr/local/lib/python3.10/dist-packages (2.5.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gTTS) (2.31.0)\n","Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gTTS) (8.1.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2023.11.17)\n","Requirement already satisfied: flask_cors in /usr/local/lib/python3.10/dist-packages (4.0.0)\n","Requirement already satisfied: Flask>=0.9 in /usr/local/lib/python3.10/dist-packages (from flask_cors) (2.2.5)\n","Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_cors) (3.0.1)\n","Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_cors) (3.1.2)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_cors) (2.1.2)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_cors) (8.1.7)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.9->flask_cors) (2.1.3)\n"]}],"source":["!pip install -q -U bitsandbytes\n","!pip install -q -U git+https://github.com/huggingface/transformers.git\n","!pip install -q -U git+https://github.com/huggingface/peft.git\n","!pip install -q -U git+https://github.com/huggingface/accelerate.git\n","!pip install -q datasets\n","!wget -q -c -nc https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip -qq -n ngrok-stable-linux-amd64.zip\n","!pip install flask-ngrok\n","!./ngrok authtoken 2ainFcf2qyBUllRP7POKymXmNi2_6vA1zUUP3bjP2EsCVKiyF\n","!pip install gTTS\n","!pip install flask_cors"]},{"cell_type":"code","source":["# ì œìœ¡ë³µìŒ\n","from datasets import load_dataset\n","import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","from peft import prepare_model_for_kbit_training\n","from peft import LoraConfig, get_peft_model\n","import transformers\n","import string\n","import re\n","from flask import Flask, request, jsonify\n","from flask_ngrok import run_with_ngrok\n","from gtts import gTTS\n","import os\n","import time\n","import base64\n","import shutil\n","from tensorflow import keras\n","import numpy as np\n","from PIL import Image\n","import io\n","from flask_cors import CORS\n","from PIL import Image, ImageOps\n","from keras.models import load_model\n","# data = load_dataset(\"beomi/KoAlpaca-v1.1a\")\n","data = load_dataset(\"mncai/MedGPT-5k-ko\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jm4FzCvfeYcK","outputId":"067f0d45-4958-4279-d63d-ccfca2b8f682","executionInfo":{"status":"ok","timestamp":1704919601457,"user_tz":-540,"elapsed":19735,"user":{"displayName":"í™©ê¸°ì„±","userId":"00510822396737292722"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z6ZSo7U9S537","executionInfo":{"status":"ok","timestamp":1704919603370,"user_tz":-540,"elapsed":1919,"user":{"displayName":"í™©ê¸°ì„±","userId":"00510822396737292722"}},"outputId":"ea68c015-ad41-4640-8272-a8ba67ed0382"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2KUhV7x3e6Db","outputId":"f4abfe62-3cdc-49d4-9749-c34eb5fc9fa5","executionInfo":{"status":"ok","timestamp":1704919603370,"user_tz":-540,"elapsed":19,"user":{"displayName":"í™©ê¸°ì„±","userId":"00510822396737292722"}}},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['instruction', 'input', 'output'],\n","        num_rows: 5304\n","    })\n","})"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["data = data.map(\n","    lambda x: {'text': f\"### ì§ˆë¬¸: {x['instruction']}\\n\\n### ë‹µë³€: {x['output']}<|endoftext|>\" })"],"metadata":{"id":"0FbgsI9sezTJ","executionInfo":{"status":"ok","timestamp":1704919603371,"user_tz":-540,"elapsed":8,"user":{"displayName":"í™©ê¸°ì„±","userId":"00510822396737292722"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# model_id = \"beomi/KoAlpaca-Polyglot-5.8B\"\n","model_id = \"beomi/polyglot-ko-12.8b-safetensors\"\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_id)\n","model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})"],"metadata":{"id":"E0Nl5mWL0k2T","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["d9749023eedf44fab71c59a9c9a6f16d","43a34912229044ee9a0872cdbb280419","9baf6ebc91ba4edda96abbf277e0e3d6","8e3da8348b9d4661a996448cf1c8af9f","afe65688079a4130be4d2b61c94bdaa0","ab1ba0164a204e56b03ec3be0359bde7","61c98a7edcd04aee818ce35f6df3de1e","7cae7169102b4981ae2785280cb4de00","42f14a7686504cc8a932f110b0333c6a","c3cfd11c6a6044dca996dee2e9b32ff0","f6901829b508423d8d482207231e6465"]},"outputId":"57acae3f-eadc-43a5-ecf5-48c39d8eb742","executionInfo":{"status":"ok","timestamp":1704919757708,"user_tz":-540,"elapsed":154344,"user":{"displayName":"í™©ê¸°ì„±","userId":"00510822396737292722"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/28 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9749023eedf44fab71c59a9c9a6f16d"}},"metadata":{}}]},{"cell_type":"code","source":["data = data.map(lambda samples: tokenizer(samples[\"text\"]), batched=True)"],"metadata":{"id":"C4TDUgDbhyhK","executionInfo":{"status":"ok","timestamp":1704919757708,"user_tz":-540,"elapsed":7,"user":{"displayName":"í™©ê¸°ì„±","userId":"00510822396737292722"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["model.gradient_checkpointing_enable()\n","model = prepare_model_for_kbit_training(model)"],"metadata":{"id":"a9EUEDAl0ss3","executionInfo":{"status":"ok","timestamp":1704919757709,"user_tz":-540,"elapsed":6,"user":{"displayName":"í™©ê¸°ì„±","userId":"00510822396737292722"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def print_trainable_parameters(model):\n","    \"\"\"\n","    Prints the number of trainable parameters in the model.\n","    \"\"\"\n","    trainable_params = 0\n","    all_param = 0\n","    for _, param in model.named_parameters():\n","        all_param += param.numel()\n","        if param.requires_grad:\n","            trainable_params += param.numel()\n","    print(\n","        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n","    )"],"metadata":{"id":"gkIcwsSU01EB","executionInfo":{"status":"ok","timestamp":1704919757709,"user_tz":-540,"elapsed":6,"user":{"displayName":"í™©ê¸°ì„±","userId":"00510822396737292722"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["config = LoraConfig(\n","    r=10,\n","    lora_alpha=40,\n","    target_modules=[\"query_key_value\"],\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\"\n",")\n","\n","model = get_peft_model(model, config)\n","print_trainable_parameters(model)"],"metadata":{"id":"Ybeyl20n3dYH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ede9b34a-1b6f-4aab-9ea7-b8e836406c76","executionInfo":{"status":"ok","timestamp":1704919758137,"user_tz":-540,"elapsed":433,"user":{"displayName":"í™©ê¸°ì„±","userId":"00510822396737292722"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["trainable params: 8192000 || all params: 6610339840 || trainable%: 0.12392706272723189\n"]}]},{"cell_type":"code","source":["tokenizer.pad_token = tokenizer.eos_token\n","\n","trainer = transformers.Trainer(\n","    model=model,\n","    train_dataset=data[\"train\"],\n","    args=transformers.TrainingArguments(\n","        per_device_train_batch_size=2,\n","        gradient_accumulation_steps=1,\n","        max_steps=1000,\n","        learning_rate=1e-4,\n","        fp16=True,\n","        logging_steps=10,\n","        output_dir=\"outputs\",\n","        optim=\"paged_adamw_8bit\"\n","    ),\n","    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",")\n","model.config.use_cache = False\n","trainer.train()\n","\n","model.eval()\n","model.config.use_cache = True"],"metadata":{"id":"jq0nX33BmfaC","colab":{"base_uri":"https://localhost:8080/","height":128},"outputId":"7d173706-9e57-4b80-f844-7045f587c38b","executionInfo":{"status":"ok","timestamp":1704919764166,"user_tz":-540,"elapsed":6031,"user":{"displayName":"í™©ê¸°ì„±","userId":"00510822396737292722"}}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1/1 00:00, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["def gen(x):\n","    prompt = f\"### ì¹œí•œ ì¹œêµ¬ì˜ ì¼ìƒì ì¸ ë§: {x}\\n\\n### ì¹œí•œ ì¹œêµ¬ì˜ ì¼ìƒì ì¸ ë§ì— ê³µê°í•˜ë©° ëŒ€ë‹µí•´ì£¼ê³  í•­ìƒ ë§ ëì— ğŸ˜€ì´ëª¨ì§€ë¥¼ ë¶™ì´ëŠ” ì¹œêµ¬:\"\n","\n","    gened = model.generate(\n","        **tokenizer(prompt, return_tensors='pt', return_token_type_ids=False),\n","        max_new_tokens=50,\n","        early_stopping=False,\n","        do_sample=True,\n","        temperature=0.5,\n","        top_k=3,\n","        eos_token_id=2,\n","    )\n","    response = tokenizer.decode(gened[0], skip_special_tokens=True)\n","\n","    response = response.replace(prompt, \"\").strip()\n","\n","    special_chars = set(string.punctuation) - set(['?', '!', '.', ','])\n","    for char in special_chars:\n","        if char in response:\n","            response = response.split(char)[0]\n","            break\n","    return response\n","gen(\"ì•„ë¬´ ë§ì´ë‚˜ í•´ì¤˜\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"2aQk19aWNtKA","executionInfo":{"status":"ok","timestamp":1704920007893,"user_tz":-540,"elapsed":12858,"user":{"displayName":"í™©ê¸°ì„±","userId":"00510822396737292722"}},"outputId":"835ebb26-a252-48be-e109-a4304af333b4"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"output_type":"execute_result","data":{"text/plain":["'ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ï¿½'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["def gen_feedback(x):\n","    prompt = f\"### ì‚¬ìš©ìëŠ” ë§í•˜ëŠ” ì—°ìŠµì„ í•˜ë ¤ê³  í•˜ëŠ” ì–´ë¦°ì•„ì´: {x}\\n\\n### ë„ˆëŠ” ì‚¬ìš©ìì˜ ë§ì— ë¬¸ì œì ì„ ë¶„ì„í•˜ê³  í”¼ë“œë°± í•´ì£¼ëŠ” AIì•¼:\"\n","\n","    gened = model.generate(\n","        **tokenizer(prompt, return_tensors='pt', return_token_type_ids=False),\n","        max_new_tokens=30,\n","        early_stopping=False,\n","        do_sample=True,\n","        temperature=0.6,\n","        top_k=5,\n","        eos_token_id=2,\n","    )\n","    response = tokenizer.decode(gened[0], skip_special_tokens=True)\n","\n","    response = response.replace(prompt, \"\").strip()\n","\n","    special_chars = set(string.punctuation) - set(['?', '!', '.', ','])\n","    for char in special_chars:\n","        if char in response:\n","            response = response.split(char)[0]\n","            break\n","    return response\n","gen_feedback(\"ì‘ ì•Œë ¤ì¤˜\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"ERlVFMcINv3m","executionInfo":{"status":"ok","timestamp":1704919779996,"user_tz":-540,"elapsed":6294,"user":{"displayName":"í™©ê¸°ì„±","userId":"00510822396737292722"}},"outputId":"3798643b-595c-4124-9357-6aa66d84db99"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"output_type":"execute_result","data":{"text/plain":["'ì‘ ê³ ë§ˆì›Œ'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["def gen_hospital(x):\n","    prompt = f\"### ë³‘ì›ì— ì§„ë£Œë¥¼ ë°›ìœ¼ëŸ¬ì˜¨ í™˜ì: {x}\\n\\n### í™˜ìì˜ ë§ì— ê³µê°í•˜ë©° ì¹œì ˆí•˜ê²Œ í•œ ë¬¸ì¥ìœ¼ë¡œ ë‹µí•´ì£¼ëŠ” ì˜ì‚¬ ì„ ìƒë‹˜:\"\n","\n","    gened = model.generate(\n","        **tokenizer(prompt, return_tensors='pt', return_token_type_ids=False),\n","        max_new_tokens=50,\n","        early_stopping=False,\n","        do_sample=True,\n","        temperature=0.6,\n","        top_k=10,\n","        eos_token_id=2,\n","    )\n","    response = tokenizer.decode(gened[0], skip_special_tokens=True)\n","\n","    response = response.replace(prompt, \"\").strip()\n","\n","    special_chars = set(string.punctuation) - set(['?', '!', '.', ','])\n","    for char in special_chars:\n","        if char in response:\n","            response = response.split(char)[0]\n","            break\n","    return response\n","gen_hospital(\"ì–´ë–¤ ê²€ì‚¬ë¥¼ í•´ì•¼í•˜ë‚˜ìš”?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"FCWDSqjtgPe3","executionInfo":{"status":"ok","timestamp":1704919789643,"user_tz":-540,"elapsed":9652,"user":{"displayName":"í™©ê¸°ì„±","userId":"00510822396737292722"}},"outputId":"5917554a-6cef-41ed-e4d1-fa8e144f494c"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"output_type":"execute_result","data":{"text/plain":["'ì–´ë–¤ ê²€ì‚¬ë¥¼ í•˜ë©´ ì¢‹ì„ì§€ ì•Œë ¤ë“œë¦´í…Œë‹ˆ ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["## ëª‡ ê°€ì§€ íŒ\n","\n","- ë§Œì•½ í•™ìŠµì´ ì¶©ë¶„íˆ ë˜ì§€ ì•Šìœ¼ë©´ `<|endoftext|>` í† í°ì´ ì˜ ìƒì„±ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤\n","- ì´ëŸ´ë–ˆ ì¶©ë¶„íˆ ê¸´ `max_new_tokens`ë¥¼ ì¤€ ë’¤, `###`ìœ¼ë¡œ ì˜ë¼ì„œ ì¨ë³´ì„¸ìš”. ex) `output.split('###')[0]`\n","- ì•„ë˜ ê²°ê³¼ëŠ” ì‹¤ì œ ìœ„ í•™ìŠµëœ(50step, 100ê°œ ìƒ˜í”Œ) ëª¨ë¸ì˜ ê²°ê³¼ë¬¼ì…ë‹ˆë‹¤.\n","- ìƒì„±ì‹œì— ì†ë„ê°€ ê½¤ ëŠë¦½ë‹ˆë‹¤. 1-2tokens/s ì •ë„ë¼ 256í† í° ìƒì„±ì‹œ ì•½ ~3ë¶„ ì‹œê°„ì´ ì†Œìš”ë©ë‹ˆë‹¤."],"metadata":{"id":"i_IDkurm8KyL"}},{"cell_type":"markdown","source":["#===============================================================================\n","# Flask part"],"metadata":{"id":"2b3ghMB843Xa"}},{"cell_type":"code","source":["if not os.path.exists(\"./gen\"):\n","    os.makedirs(\"./gen\")\n","\n","if not os.path.exists(\"./gen_feedback\"):\n","    os.makedirs(\"./gen_feedback\")\n","\n","if not os.path.exists(\"./gen_hospital\"):\n","    os.makedirs(\"./gen_hospital\")"],"metadata":{"id":"dHApqUoJlRZY","executionInfo":{"status":"ok","timestamp":1704919789644,"user_tz":-540,"elapsed":7,"user":{"displayName":"í™©ê¸°ì„±","userId":"00510822396737292722"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["np.set_printoptions(suppress=True)\n","\n","model_img = load_model(\"/content/keras_model.h5\", compile=False)\n","\n","class_names = open(\"/content/labels.txt\", \"r\").readlines()"],"metadata":{"id":"Y3PJjux85zL5","executionInfo":{"status":"ok","timestamp":1704919793156,"user_tz":-540,"elapsed":3517,"user":{"displayName":"í™©ê¸°ì„±","userId":"00510822396737292722"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf"],"metadata":{"id":"t9rm5m857p0b","executionInfo":{"status":"ok","timestamp":1704919793157,"user_tz":-540,"elapsed":7,"user":{"displayName":"í™©ê¸°ì„±","userId":"00510822396737292722"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# ëŒ€í™”\n","def gen(x, ch):\n","  if ch == 0:\n","    prompt = f\"### ì¹œí•œ ì¹œêµ¬ì˜ ì¼ìƒì ì¸ ë§: {x}\\n\\n### ì¹œí•œ ì¹œêµ¬ì˜ ì¼ìƒì ì¸ ë§ì— ê³µê°í•˜ë©° ëŒ€ë‹µí•´ì£¼ëŠ” ì¹œêµ¬ì˜ ë‹µë³€:\"\n","  elif ch == 1:\n","    prompt = f\"### ì¹œí•œ ì¹œêµ¬ì˜ ì¼ìƒì ì¸ ë§: {x}\\n\\n### ì¹œí•œ ì¹œêµ¬ì˜ ì¼ìƒì ì¸ ë§ì— ê³µê°í•˜ë©° ëŒ€ë‹µí•´ì£¼ê³  ë§ ëì— í•­ìƒ ğŸ˜ƒì´ëª¨ì§€ë¥¼ ë¶™ì´ëŠ” ì¹œêµ¬:\"\n","  else:\n","    return \"ì½ê¸° ë¶ˆê°€\"\n","\n","  gened = model.generate(\n","        **tokenizer(prompt, return_tensors='pt', return_token_type_ids=False),\n","        max_new_tokens=30,\n","        early_stopping=False,\n","        do_sample=True,\n","        temperature=0.6,\n","        top_k=5,\n","        eos_token_id=2,\n","    )\n","  response = tokenizer.decode(gened[0], skip_special_tokens=True)\n","\n","  response = response.replace(prompt, \"\").strip()\n","\n","  special_chars = set(string.punctuation) - set(['?', '!', '.', ','])\n","  for char in special_chars:\n","      if char in response:\n","          response = response.split(char)[0]\n","          break\n","  return response\n","\n","\n","# í”¼ë“œë°±\n","def gen_feedback(x):\n","    prompt = f\"### ì‚¬ëŒë“¤ê³¼ ë§í•˜ëŠ” ëŠ¥ë ¥ì„ í‚¤ìš°ë ¤ê³  ì—°ìŠµí•˜ëŠ” ì¹œêµ¬: {x}\\n\\n### ì¹œêµ¬ì˜ ë§ì— í”¼ë“œë°± í•´ì£¼ê³  ì˜ˆì‹œ ë‹µë³€ì„ ì´ì•¼ê¸° í•´ì£¼ë©° ë§í•˜ëŠ” ì—°ìŠµì„ í•˜ëŠ” ì¹œêµ¬ë¥¼ ë„ì™€ì£¼ëŠ” ì¹œêµ¬:\"\n","\n","    gened = model.generate(\n","        **tokenizer(prompt, return_tensors='pt', return_token_type_ids=False),\n","        max_new_tokens=30,\n","        early_stopping=False,\n","        do_sample=True,\n","        temperature=0.6,\n","        top_k=5,\n","        eos_token_id=2,\n","    )\n","    response = tokenizer.decode(gened[0], skip_special_tokens=True)\n","\n","    response = response.replace(prompt, \"\").strip()\n","\n","    special_chars = set(string.punctuation) - set(['?', '!', '.', ','])\n","    for char in special_chars:\n","        if char in response:\n","            response = response.split(char)[0]\n","            break\n","    return response\n","\n","\n","# ìƒí™©ê·¹\n","def gen_hospital(x):\n","    prompt = f\"### ë³‘ì›ì— ì§„ë£Œë¥¼ ë°›ìœ¼ëŸ¬ì˜¨ í™˜ì: {x}\\n\\n### í™˜ìì˜ ë§ì— ê³µê°í•˜ë©° ì¹œì ˆí•˜ê²Œ í•œ ë¬¸ì¥ìœ¼ë¡œ ë‹µí•´ì£¼ëŠ” ì˜ì‚¬ ì„ ìƒë‹˜:\"\n","\n","    gened = model.generate(\n","        **tokenizer(prompt, return_tensors='pt', return_token_type_ids=False),\n","        max_new_tokens=30,\n","        early_stopping=False,\n","        do_sample=True,\n","        temperature=0.6,\n","        top_k=5,\n","        eos_token_id=2,\n","    )\n","    response = tokenizer.decode(gened[0], skip_special_tokens=True)\n","\n","    response = response.replace(prompt, \"\").strip()\n","\n","    special_chars = set(string.punctuation) - set(['?', '!', '.', ','])\n","    for char in special_chars:\n","        if char in response:\n","            response = response.split(char)[0]\n","            break\n","    return response\n","\n","app = Flask(__name__)\n","CORS(run_with_ngrok(app))\n","\n","# ëŒ€í™”\n","@app.route('/ai/gen', methods=['POST'])\n","def gen_text():\n","    data = request.get_json()\n","    text = data.get('text')\n","    ch = int(text[-1])\n","    text = str(text[:-1])\n","    result = gen(text, ch)\n","    result = str(result)\n","    print(type(result))\n","    modified_result = re.sub(r\"[^\\w\\s\\.\\?,]\", \"\", result)\n","    language = 'ko'\n","    timestamp = int(time.time())\n","    filename = f\"/content/gen/{timestamp}.mp3\"\n","    myobj = gTTS(text=result, lang=language, slow=False)\n","    myobj.save(filename)\n","    with open(filename, \"rb\") as audio_file:\n","      encoded = base64.b64encode(audio_file.read()).decode('utf-8')\n","    return jsonify({\"audio\": encoded, \"text\": result})\n","\n","# í”¼ë“œë°±\n","@app.route('/ai/gen_feedback', methods=['POST'])\n","def gen_feedback_text():\n","    data = request.get_json()\n","    text = data.get('text')\n","    result = gen_feedback(text)\n","    modified_result = re.sub(r\"[^\\w\\s\\.\\?,]\", \"\", result)\n","    language = 'ko'\n","    timestamp = int(time.time())\n","    filename = f\"/content/gen_feedback/{timestamp}.mp3\"\n","    myobj = gTTS(text=modified_result, lang=language, slow=False)\n","    myobj.save(filename)\n","    with open(filename, \"rb\") as audio_file:\n","      encoded = base64.b64encode(audio_file.read()).decode('utf-8')\n","    return jsonify({\"audio\": encoded, \"text\": modified_result})\n","\n","\n","# ìƒí™©ê·¹\n","@app.route('/ai/gen_hospital', methods=['POST'])\n","def gen_hospital_text():\n","    data = request.get_json()\n","    text = data.get('text')\n","    result = gen_hospital(text)\n","    modified_result = re.sub(r\"[^\\w\\s\\.\\?,]\", \"\", result)\n","    language = 'ko'\n","    timestamp = int(time.time())\n","    filename = f\"/content/gen_hospital/{timestamp}.mp3\"\n","    myobj = gTTS(text=modified_result, lang=language, slow=False)\n","    myobj.save(filename)\n","    with open(filename, \"rb\") as audio_file:\n","      encoded = base64.b64encode(audio_file.read()).decode('utf-8')\n","    return jsonify({\"audio\": encoded, \"text\": modified_result})\n","\n","\n","def preprocess_image(base64_string):\n","    image_data = base64.b64decode(base64_string)\n","    image = Image.open(io.BytesIO(image_data))\n","    image = image.convert(\"RGB\")\n","    size = (224, 224)\n","    image = ImageOps.fit(image, size, Image.Resampling.LANCZOS)\n","    image_array = np.asarray(image)\n","    normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n","    return np.expand_dims(normalized_image_array, axis=0)\n","\n","\n","# ì‹œì„ ì²˜ë¦¬\n","@app.route('/ai/img', methods=['POST'])\n","def process_text():\n","    image_data = request.json['image']\n","    preprocessed_image_eme = preprocess_image(image_data)\n","    prediction = model_img.predict(preprocessed_image_eme)\n","    result = np.argmax(prediction, axis=1)\n","    return {\"key\": f\"{result}\"}\n","\n","if __name__ == '__main__':\n","    app.run()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AnlC8vKU4-k8","outputId":"76943a69-e8e3-43d0-8767-a85d88bcdba9","executionInfo":{"status":"ok","timestamp":1704921912648,"user_tz":-540,"elapsed":78010,"user":{"displayName":"í™©ê¸°ì„±","userId":"00510822396737292722"}}},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":[" * Serving Flask app '__main__'\n"," * Debug mode: off\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n"," * Running on http://127.0.0.1:5000\n","INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":[" * Running on http://5860-34-66-209-39.ngrok-free.app\n"," * Traffic stats available on http://127.0.0.1:4040\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1665: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["<class 'str'>\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug:127.0.0.1 - - [10/Jan/2024 21:25:04] \"POST /ai/gen HTTP/1.1\" 200 -\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"nHkSpv1sQqEj"},"execution_count":null,"outputs":[]}]}