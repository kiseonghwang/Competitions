{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d9749023eedf44fab71c59a9c9a6f16d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_43a34912229044ee9a0872cdbb280419","IPY_MODEL_9baf6ebc91ba4edda96abbf277e0e3d6","IPY_MODEL_8e3da8348b9d4661a996448cf1c8af9f"],"layout":"IPY_MODEL_afe65688079a4130be4d2b61c94bdaa0"}},"43a34912229044ee9a0872cdbb280419":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab1ba0164a204e56b03ec3be0359bde7","placeholder":"​","style":"IPY_MODEL_61c98a7edcd04aee818ce35f6df3de1e","value":"Loading checkpoint shards: 100%"}},"9baf6ebc91ba4edda96abbf277e0e3d6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7cae7169102b4981ae2785280cb4de00","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_42f14a7686504cc8a932f110b0333c6a","value":28}},"8e3da8348b9d4661a996448cf1c8af9f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3cfd11c6a6044dca996dee2e9b32ff0","placeholder":"​","style":"IPY_MODEL_f6901829b508423d8d482207231e6465","value":" 28/28 [02:28&lt;00:00,  4.66s/it]"}},"afe65688079a4130be4d2b61c94bdaa0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab1ba0164a204e56b03ec3be0359bde7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61c98a7edcd04aee818ce35f6df3de1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7cae7169102b4981ae2785280cb4de00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42f14a7686504cc8a932f110b0333c6a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c3cfd11c6a6044dca996dee2e9b32ff0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6901829b508423d8d482207231e6465":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"FuXIFTFapAMI","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4653e8fe-2c4b-43ef-fc82-b8c997feb148","executionInfo":{"status":"ok","timestamp":1704919581764,"user_tz":-540,"elapsed":99232,"user":{"displayName":"황기성","userId":"00510822396737292722"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.10/dist-packages (0.0.25)\n","Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.2.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.31.0)\n","Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (3.0.1)\n","Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.2)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (2.1.2)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (8.1.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2023.11.17)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.8->flask-ngrok) (2.1.3)\n","Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n","Requirement already satisfied: gTTS in /usr/local/lib/python3.10/dist-packages (2.5.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gTTS) (2.31.0)\n","Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gTTS) (8.1.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2023.11.17)\n","Requirement already satisfied: flask_cors in /usr/local/lib/python3.10/dist-packages (4.0.0)\n","Requirement already satisfied: Flask>=0.9 in /usr/local/lib/python3.10/dist-packages (from flask_cors) (2.2.5)\n","Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_cors) (3.0.1)\n","Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_cors) (3.1.2)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_cors) (2.1.2)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_cors) (8.1.7)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.9->flask_cors) (2.1.3)\n"]}],"source":["!pip install -q -U bitsandbytes\n","!pip install -q -U git+https://github.com/huggingface/transformers.git\n","!pip install -q -U git+https://github.com/huggingface/peft.git\n","!pip install -q -U git+https://github.com/huggingface/accelerate.git\n","!pip install -q datasets\n","!wget -q -c -nc https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip -qq -n ngrok-stable-linux-amd64.zip\n","!pip install flask-ngrok\n","!./ngrok authtoken 2ainFcf2qyBUllRP7POKymXmNi2_6vA1zUUP3bjP2EsCVKiyF\n","!pip install gTTS\n","!pip install flask_cors"]},{"cell_type":"code","source":["# 제육복음\n","from datasets import load_dataset\n","import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","from peft import prepare_model_for_kbit_training\n","from peft import LoraConfig, get_peft_model\n","import transformers\n","import string\n","import re\n","from flask import Flask, request, jsonify\n","from flask_ngrok import run_with_ngrok\n","from gtts import gTTS\n","import os\n","import time\n","import base64\n","import shutil\n","from tensorflow import keras\n","import numpy as np\n","from PIL import Image\n","import io\n","from flask_cors import CORS\n","from PIL import Image, ImageOps\n","from keras.models import load_model\n","# data = load_dataset(\"beomi/KoAlpaca-v1.1a\")\n","data = load_dataset(\"mncai/MedGPT-5k-ko\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jm4FzCvfeYcK","outputId":"067f0d45-4958-4279-d63d-ccfca2b8f682","executionInfo":{"status":"ok","timestamp":1704919601457,"user_tz":-540,"elapsed":19735,"user":{"displayName":"황기성","userId":"00510822396737292722"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z6ZSo7U9S537","executionInfo":{"status":"ok","timestamp":1704919603370,"user_tz":-540,"elapsed":1919,"user":{"displayName":"황기성","userId":"00510822396737292722"}},"outputId":"ea68c015-ad41-4640-8272-a8ba67ed0382"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2KUhV7x3e6Db","outputId":"f4abfe62-3cdc-49d4-9749-c34eb5fc9fa5","executionInfo":{"status":"ok","timestamp":1704919603370,"user_tz":-540,"elapsed":19,"user":{"displayName":"황기성","userId":"00510822396737292722"}}},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['instruction', 'input', 'output'],\n","        num_rows: 5304\n","    })\n","})"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["data = data.map(\n","    lambda x: {'text': f\"### 질문: {x['instruction']}\\n\\n### 답변: {x['output']}<|endoftext|>\" })"],"metadata":{"id":"0FbgsI9sezTJ","executionInfo":{"status":"ok","timestamp":1704919603371,"user_tz":-540,"elapsed":8,"user":{"displayName":"황기성","userId":"00510822396737292722"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# model_id = \"beomi/KoAlpaca-Polyglot-5.8B\"\n","model_id = \"beomi/polyglot-ko-12.8b-safetensors\"\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_id)\n","model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})"],"metadata":{"id":"E0Nl5mWL0k2T","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["d9749023eedf44fab71c59a9c9a6f16d","43a34912229044ee9a0872cdbb280419","9baf6ebc91ba4edda96abbf277e0e3d6","8e3da8348b9d4661a996448cf1c8af9f","afe65688079a4130be4d2b61c94bdaa0","ab1ba0164a204e56b03ec3be0359bde7","61c98a7edcd04aee818ce35f6df3de1e","7cae7169102b4981ae2785280cb4de00","42f14a7686504cc8a932f110b0333c6a","c3cfd11c6a6044dca996dee2e9b32ff0","f6901829b508423d8d482207231e6465"]},"outputId":"57acae3f-eadc-43a5-ecf5-48c39d8eb742","executionInfo":{"status":"ok","timestamp":1704919757708,"user_tz":-540,"elapsed":154344,"user":{"displayName":"황기성","userId":"00510822396737292722"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/28 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9749023eedf44fab71c59a9c9a6f16d"}},"metadata":{}}]},{"cell_type":"code","source":["data = data.map(lambda samples: tokenizer(samples[\"text\"]), batched=True)"],"metadata":{"id":"C4TDUgDbhyhK","executionInfo":{"status":"ok","timestamp":1704919757708,"user_tz":-540,"elapsed":7,"user":{"displayName":"황기성","userId":"00510822396737292722"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["model.gradient_checkpointing_enable()\n","model = prepare_model_for_kbit_training(model)"],"metadata":{"id":"a9EUEDAl0ss3","executionInfo":{"status":"ok","timestamp":1704919757709,"user_tz":-540,"elapsed":6,"user":{"displayName":"황기성","userId":"00510822396737292722"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def print_trainable_parameters(model):\n","    \"\"\"\n","    Prints the number of trainable parameters in the model.\n","    \"\"\"\n","    trainable_params = 0\n","    all_param = 0\n","    for _, param in model.named_parameters():\n","        all_param += param.numel()\n","        if param.requires_grad:\n","            trainable_params += param.numel()\n","    print(\n","        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n","    )"],"metadata":{"id":"gkIcwsSU01EB","executionInfo":{"status":"ok","timestamp":1704919757709,"user_tz":-540,"elapsed":6,"user":{"displayName":"황기성","userId":"00510822396737292722"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["config = LoraConfig(\n","    r=10,\n","    lora_alpha=40,\n","    target_modules=[\"query_key_value\"],\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\"\n",")\n","\n","model = get_peft_model(model, config)\n","print_trainable_parameters(model)"],"metadata":{"id":"Ybeyl20n3dYH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ede9b34a-1b6f-4aab-9ea7-b8e836406c76","executionInfo":{"status":"ok","timestamp":1704919758137,"user_tz":-540,"elapsed":433,"user":{"displayName":"황기성","userId":"00510822396737292722"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["trainable params: 8192000 || all params: 6610339840 || trainable%: 0.12392706272723189\n"]}]},{"cell_type":"code","source":["tokenizer.pad_token = tokenizer.eos_token\n","\n","trainer = transformers.Trainer(\n","    model=model,\n","    train_dataset=data[\"train\"],\n","    args=transformers.TrainingArguments(\n","        per_device_train_batch_size=2,\n","        gradient_accumulation_steps=1,\n","        max_steps=1000,\n","        learning_rate=1e-4,\n","        fp16=True,\n","        logging_steps=10,\n","        output_dir=\"outputs\",\n","        optim=\"paged_adamw_8bit\"\n","    ),\n","    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",")\n","model.config.use_cache = False\n","trainer.train()\n","\n","model.eval()\n","model.config.use_cache = True"],"metadata":{"id":"jq0nX33BmfaC","colab":{"base_uri":"https://localhost:8080/","height":128},"outputId":"7d173706-9e57-4b80-f844-7045f587c38b","executionInfo":{"status":"ok","timestamp":1704919764166,"user_tz":-540,"elapsed":6031,"user":{"displayName":"황기성","userId":"00510822396737292722"}}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1/1 00:00, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["def gen(x):\n","    prompt = f\"### 친한 친구의 일상적인 말: {x}\\n\\n### 친한 친구의 일상적인 말에 공감하며 대답해주고 항상 말 끝에 😀이모지를 붙이는 친구:\"\n","\n","    gened = model.generate(\n","        **tokenizer(prompt, return_tensors='pt', return_token_type_ids=False),\n","        max_new_tokens=50,\n","        early_stopping=False,\n","        do_sample=True,\n","        temperature=0.5,\n","        top_k=3,\n","        eos_token_id=2,\n","    )\n","    response = tokenizer.decode(gened[0], skip_special_tokens=True)\n","\n","    response = response.replace(prompt, \"\").strip()\n","\n","    special_chars = set(string.punctuation) - set(['?', '!', '.', ','])\n","    for char in special_chars:\n","        if char in response:\n","            response = response.split(char)[0]\n","            break\n","    return response\n","gen(\"아무 말이나 해줘\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"2aQk19aWNtKA","executionInfo":{"status":"ok","timestamp":1704920007893,"user_tz":-540,"elapsed":12858,"user":{"displayName":"황기성","userId":"00510822396737292722"}},"outputId":"835ebb26-a252-48be-e109-a4304af333b4"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"output_type":"execute_result","data":{"text/plain":["'😀😀😀😀😀😀😀😀😀😀😀😀�'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["def gen_feedback(x):\n","    prompt = f\"### 사용자는 말하는 연습을 하려고 하는 어린아이: {x}\\n\\n### 너는 사용자의 말에 문제점을 분석하고 피드백 해주는 AI야:\"\n","\n","    gened = model.generate(\n","        **tokenizer(prompt, return_tensors='pt', return_token_type_ids=False),\n","        max_new_tokens=30,\n","        early_stopping=False,\n","        do_sample=True,\n","        temperature=0.6,\n","        top_k=5,\n","        eos_token_id=2,\n","    )\n","    response = tokenizer.decode(gened[0], skip_special_tokens=True)\n","\n","    response = response.replace(prompt, \"\").strip()\n","\n","    special_chars = set(string.punctuation) - set(['?', '!', '.', ','])\n","    for char in special_chars:\n","        if char in response:\n","            response = response.split(char)[0]\n","            break\n","    return response\n","gen_feedback(\"응 알려줘\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"ERlVFMcINv3m","executionInfo":{"status":"ok","timestamp":1704919779996,"user_tz":-540,"elapsed":6294,"user":{"displayName":"황기성","userId":"00510822396737292722"}},"outputId":"3798643b-595c-4124-9357-6aa66d84db99"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"output_type":"execute_result","data":{"text/plain":["'응 고마워'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["def gen_hospital(x):\n","    prompt = f\"### 병원에 진료를 받으러온 환자: {x}\\n\\n### 환자의 말에 공감하며 친절하게 한 문장으로 답해주는 의사 선생님:\"\n","\n","    gened = model.generate(\n","        **tokenizer(prompt, return_tensors='pt', return_token_type_ids=False),\n","        max_new_tokens=50,\n","        early_stopping=False,\n","        do_sample=True,\n","        temperature=0.6,\n","        top_k=10,\n","        eos_token_id=2,\n","    )\n","    response = tokenizer.decode(gened[0], skip_special_tokens=True)\n","\n","    response = response.replace(prompt, \"\").strip()\n","\n","    special_chars = set(string.punctuation) - set(['?', '!', '.', ','])\n","    for char in special_chars:\n","        if char in response:\n","            response = response.split(char)[0]\n","            break\n","    return response\n","gen_hospital(\"어떤 검사를 해야하나요?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"FCWDSqjtgPe3","executionInfo":{"status":"ok","timestamp":1704919789643,"user_tz":-540,"elapsed":9652,"user":{"displayName":"황기성","userId":"00510822396737292722"}},"outputId":"5917554a-6cef-41ed-e4d1-fa8e144f494c"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"output_type":"execute_result","data":{"text/plain":["'어떤 검사를 하면 좋을지 알려드릴테니 잠시만 기다려 주세요.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["## 몇 가지 팁\n","\n","- 만약 학습이 충분히 되지 않으면 `<|endoftext|>` 토큰이 잘 생성되지 않을 수 있습니다\n","- 이럴떈 충분히 긴 `max_new_tokens`를 준 뒤, `###`으로 잘라서 써보세요. ex) `output.split('###')[0]`\n","- 아래 결과는 실제 위 학습된(50step, 100개 샘플) 모델의 결과물입니다.\n","- 생성시에 속도가 꽤 느립니다. 1-2tokens/s 정도라 256토큰 생성시 약 ~3분 시간이 소요됩니다."],"metadata":{"id":"i_IDkurm8KyL"}},{"cell_type":"markdown","source":["#===============================================================================\n","# Flask part"],"metadata":{"id":"2b3ghMB843Xa"}},{"cell_type":"code","source":["if not os.path.exists(\"./gen\"):\n","    os.makedirs(\"./gen\")\n","\n","if not os.path.exists(\"./gen_feedback\"):\n","    os.makedirs(\"./gen_feedback\")\n","\n","if not os.path.exists(\"./gen_hospital\"):\n","    os.makedirs(\"./gen_hospital\")"],"metadata":{"id":"dHApqUoJlRZY","executionInfo":{"status":"ok","timestamp":1704919789644,"user_tz":-540,"elapsed":7,"user":{"displayName":"황기성","userId":"00510822396737292722"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["np.set_printoptions(suppress=True)\n","\n","model_img = load_model(\"/content/keras_model.h5\", compile=False)\n","\n","class_names = open(\"/content/labels.txt\", \"r\").readlines()"],"metadata":{"id":"Y3PJjux85zL5","executionInfo":{"status":"ok","timestamp":1704919793156,"user_tz":-540,"elapsed":3517,"user":{"displayName":"황기성","userId":"00510822396737292722"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf"],"metadata":{"id":"t9rm5m857p0b","executionInfo":{"status":"ok","timestamp":1704919793157,"user_tz":-540,"elapsed":7,"user":{"displayName":"황기성","userId":"00510822396737292722"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# 대화\n","def gen(x, ch):\n","  if ch == 0:\n","    prompt = f\"### 친한 친구의 일상적인 말: {x}\\n\\n### 친한 친구의 일상적인 말에 공감하며 대답해주는 친구의 답변:\"\n","  elif ch == 1:\n","    prompt = f\"### 친한 친구의 일상적인 말: {x}\\n\\n### 친한 친구의 일상적인 말에 공감하며 대답해주고 말 끝에 항상 😃이모지를 붙이는 친구:\"\n","  else:\n","    return \"읽기 불가\"\n","\n","  gened = model.generate(\n","        **tokenizer(prompt, return_tensors='pt', return_token_type_ids=False),\n","        max_new_tokens=30,\n","        early_stopping=False,\n","        do_sample=True,\n","        temperature=0.6,\n","        top_k=5,\n","        eos_token_id=2,\n","    )\n","  response = tokenizer.decode(gened[0], skip_special_tokens=True)\n","\n","  response = response.replace(prompt, \"\").strip()\n","\n","  special_chars = set(string.punctuation) - set(['?', '!', '.', ','])\n","  for char in special_chars:\n","      if char in response:\n","          response = response.split(char)[0]\n","          break\n","  return response\n","\n","\n","# 피드백\n","def gen_feedback(x):\n","    prompt = f\"### 사람들과 말하는 능력을 키우려고 연습하는 친구: {x}\\n\\n### 친구의 말에 피드백 해주고 예시 답변을 이야기 해주며 말하는 연습을 하는 친구를 도와주는 친구:\"\n","\n","    gened = model.generate(\n","        **tokenizer(prompt, return_tensors='pt', return_token_type_ids=False),\n","        max_new_tokens=30,\n","        early_stopping=False,\n","        do_sample=True,\n","        temperature=0.6,\n","        top_k=5,\n","        eos_token_id=2,\n","    )\n","    response = tokenizer.decode(gened[0], skip_special_tokens=True)\n","\n","    response = response.replace(prompt, \"\").strip()\n","\n","    special_chars = set(string.punctuation) - set(['?', '!', '.', ','])\n","    for char in special_chars:\n","        if char in response:\n","            response = response.split(char)[0]\n","            break\n","    return response\n","\n","\n","# 상황극\n","def gen_hospital(x):\n","    prompt = f\"### 병원에 진료를 받으러온 환자: {x}\\n\\n### 환자의 말에 공감하며 친절하게 한 문장으로 답해주는 의사 선생님:\"\n","\n","    gened = model.generate(\n","        **tokenizer(prompt, return_tensors='pt', return_token_type_ids=False),\n","        max_new_tokens=30,\n","        early_stopping=False,\n","        do_sample=True,\n","        temperature=0.6,\n","        top_k=5,\n","        eos_token_id=2,\n","    )\n","    response = tokenizer.decode(gened[0], skip_special_tokens=True)\n","\n","    response = response.replace(prompt, \"\").strip()\n","\n","    special_chars = set(string.punctuation) - set(['?', '!', '.', ','])\n","    for char in special_chars:\n","        if char in response:\n","            response = response.split(char)[0]\n","            break\n","    return response\n","\n","app = Flask(__name__)\n","CORS(run_with_ngrok(app))\n","\n","# 대화\n","@app.route('/ai/gen', methods=['POST'])\n","def gen_text():\n","    data = request.get_json()\n","    text = data.get('text')\n","    ch = int(text[-1])\n","    text = str(text[:-1])\n","    result = gen(text, ch)\n","    result = str(result)\n","    print(type(result))\n","    modified_result = re.sub(r\"[^\\w\\s\\.\\?,]\", \"\", result)\n","    language = 'ko'\n","    timestamp = int(time.time())\n","    filename = f\"/content/gen/{timestamp}.mp3\"\n","    myobj = gTTS(text=result, lang=language, slow=False)\n","    myobj.save(filename)\n","    with open(filename, \"rb\") as audio_file:\n","      encoded = base64.b64encode(audio_file.read()).decode('utf-8')\n","    return jsonify({\"audio\": encoded, \"text\": result})\n","\n","# 피드백\n","@app.route('/ai/gen_feedback', methods=['POST'])\n","def gen_feedback_text():\n","    data = request.get_json()\n","    text = data.get('text')\n","    result = gen_feedback(text)\n","    modified_result = re.sub(r\"[^\\w\\s\\.\\?,]\", \"\", result)\n","    language = 'ko'\n","    timestamp = int(time.time())\n","    filename = f\"/content/gen_feedback/{timestamp}.mp3\"\n","    myobj = gTTS(text=modified_result, lang=language, slow=False)\n","    myobj.save(filename)\n","    with open(filename, \"rb\") as audio_file:\n","      encoded = base64.b64encode(audio_file.read()).decode('utf-8')\n","    return jsonify({\"audio\": encoded, \"text\": modified_result})\n","\n","\n","# 상황극\n","@app.route('/ai/gen_hospital', methods=['POST'])\n","def gen_hospital_text():\n","    data = request.get_json()\n","    text = data.get('text')\n","    result = gen_hospital(text)\n","    modified_result = re.sub(r\"[^\\w\\s\\.\\?,]\", \"\", result)\n","    language = 'ko'\n","    timestamp = int(time.time())\n","    filename = f\"/content/gen_hospital/{timestamp}.mp3\"\n","    myobj = gTTS(text=modified_result, lang=language, slow=False)\n","    myobj.save(filename)\n","    with open(filename, \"rb\") as audio_file:\n","      encoded = base64.b64encode(audio_file.read()).decode('utf-8')\n","    return jsonify({\"audio\": encoded, \"text\": modified_result})\n","\n","\n","def preprocess_image(base64_string):\n","    image_data = base64.b64decode(base64_string)\n","    image = Image.open(io.BytesIO(image_data))\n","    image = image.convert(\"RGB\")\n","    size = (224, 224)\n","    image = ImageOps.fit(image, size, Image.Resampling.LANCZOS)\n","    image_array = np.asarray(image)\n","    normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n","    return np.expand_dims(normalized_image_array, axis=0)\n","\n","\n","# 시선처리\n","@app.route('/ai/img', methods=['POST'])\n","def process_text():\n","    image_data = request.json['image']\n","    preprocessed_image_eme = preprocess_image(image_data)\n","    prediction = model_img.predict(preprocessed_image_eme)\n","    result = np.argmax(prediction, axis=1)\n","    return {\"key\": f\"{result}\"}\n","\n","if __name__ == '__main__':\n","    app.run()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AnlC8vKU4-k8","outputId":"76943a69-e8e3-43d0-8767-a85d88bcdba9","executionInfo":{"status":"ok","timestamp":1704921912648,"user_tz":-540,"elapsed":78010,"user":{"displayName":"황기성","userId":"00510822396737292722"}}},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":[" * Serving Flask app '__main__'\n"," * Debug mode: off\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n"," * Running on http://127.0.0.1:5000\n","INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":[" * Running on http://5860-34-66-209-39.ngrok-free.app\n"," * Traffic stats available on http://127.0.0.1:4040\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1665: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["<class 'str'>\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug:127.0.0.1 - - [10/Jan/2024 21:25:04] \"POST /ai/gen HTTP/1.1\" 200 -\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"nHkSpv1sQqEj"},"execution_count":null,"outputs":[]}]}